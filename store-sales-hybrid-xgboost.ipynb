{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport datetime\nimport scipy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_log_error\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-17T13:44:21.924793Z","iopub.execute_input":"2022-07-17T13:44:21.925560Z","iopub.status.idle":"2022-07-17T13:44:23.795314Z","shell.execute_reply.started":"2022-07-17T13:44:21.925425Z","shell.execute_reply":"2022-07-17T13:44:23.793983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True, figsize=(11, 4))\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,\n)\nplot_params = dict(\n    color=\"0.75\",\n    style=\".-\",\n    markeredgecolor=\"0.25\",\n    markerfacecolor=\"0.25\",\n    legend=False,\n)\n%config InlineBackend.figure_format = 'retina'\n\ndef truncateFloat(data):\n    return tuple( [\"{0:.2f}\".format(x) if isinstance(x,float) else (x if not isinstance(x,tuple) else truncateFloat(x)) for x in data])","metadata":{"execution":{"iopub.status.busy":"2022-07-17T13:44:23.798993Z","iopub.execute_input":"2022-07-17T13:44:23.799894Z","iopub.status.idle":"2022-07-17T13:44:23.829584Z","shell.execute_reply.started":"2022-07-17T13:44:23.799844Z","shell.execute_reply":"2022-07-17T13:44:23.828230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load Files","metadata":{}},{"cell_type":"code","source":"IN_FP = '../input/store-sales-time-series-forecasting'\nTRAIN_FP = os.path.join(IN_FP, 'train.csv')\nTEST_FP = os.path.join(IN_FP, 'test.csv')\nHOLIDAYS_FP = os.path.join(IN_FP, 'holidays_events.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-17T13:44:23.831491Z","iopub.execute_input":"2022-07-17T13:44:23.831940Z","iopub.status.idle":"2022-07-17T13:44:23.837986Z","shell.execute_reply.started":"2022-07-17T13:44:23.831900Z","shell.execute_reply":"2022-07-17T13:44:23.837088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"store_sales = pd.read_csv(\n    TRAIN_FP,\n    usecols=['store_nbr', 'family', 'date', 'sales', 'onpromotion'],\n    dtype={\n        'store_nbr': 'category',\n        'family': 'category',\n        'sales': 'float32',\n        'onpromotion': 'uint32',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\n\nstore_sales['date'] = store_sales.date.dt.to_period('D')\n\nm_index = pd.MultiIndex.from_product([store_sales[\"store_nbr\"].unique(),\n                                      store_sales[\"family\"].unique(),\n                                      pd.date_range(start=\"2013-1-1\", end=\"2017-8-15\", freq=\"D\").to_period('D')] # to get missing Christmas Days\n                                     ,names=[\"store_nbr\",\"family\", \"date\"])\nstore_sales = store_sales.set_index([\"store_nbr\",\"family\", \"date\"]).reindex(m_index, fill_value=0).sort_index()\n\nstore_sales = store_sales.unstack(['store_nbr', 'family']).fillna(0) # there are lots!\nstore_sales = store_sales.stack(['store_nbr', 'family'])\nstore_sales = store_sales[['sales','onpromotion']]\n\ntest = pd.read_csv(\n    TEST_FP,\n    dtype={\n        'store_nbr': 'category',\n        'family': 'category',\n        'onpromotion': 'uint32',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\n\ntest['date'] = test.date.dt.to_period('D')\ntest = test.set_index(['store_nbr', 'family', 'date']).sort_index()\n\nholidays_events = pd.read_csv(\n    HOLIDAYS_FP,\n    dtype={\n        'type': 'category',\n        'locale': 'category',\n        'locale_name': 'category',\n        'description': 'category',\n        'transferred': 'bool',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\nholidays_events['date'] = holidays_events['date'].replace({'2013-04-29':pd.to_datetime('2013-03-29')})\nholidays_events = holidays_events.set_index('date').to_period('D')","metadata":{"execution":{"iopub.status.busy":"2022-07-17T13:44:23.840428Z","iopub.execute_input":"2022-07-17T13:44:23.841027Z","iopub.status.idle":"2022-07-17T13:45:02.812019Z","shell.execute_reply.started":"2022-07-17T13:44:23.840973Z","shell.execute_reply":"2022-07-17T13:45:02.810417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create Calender","metadata":{}},{"cell_type":"code","source":"# Creating workday calender using holidays\n# https://www.kaggle.com/dkomyagin/simple-ts-ridge-rf\n\ncalender = pd.DataFrame(index=pd.date_range('2013-01-01', '2017-08-31')).to_period('D')\ncalender['dofw'] = calender.index.dayofweek\n\ndf_hev = holidays_events[holidays_events.locale == 'National']  # Only considering national holidays in this instance\ndf_hev = df_hev.groupby(df_hev.index).first()\n\ncalender['wd'] = True\ncalender.loc[calender.dofw > 4, 'wd'] = False  # Omit weekends\n\ncalender = calender.merge(df_hev, how='left', left_index=True, right_index=True)\n\ncalender.loc[calender.type == 'Bridge', 'wd'] = False\ncalender.loc[calender.type == 'Work Day', 'wd'] = True\ncalender.loc[calender.type == 'Transfer', 'wd'] = False\ncalender.loc[(calender.type == 'Holiday') & (calender.transferred == False), 'wd'] = False\ncalender.loc[(calender.type == 'Holiday') & (calender.transferred == True), 'wd'] = True","metadata":{"execution":{"iopub.status.busy":"2022-07-17T13:45:02.814229Z","iopub.execute_input":"2022-07-17T13:45:02.814749Z","iopub.status.idle":"2022-07-17T13:45:02.900037Z","shell.execute_reply.started":"2022-07-17T13:45:02.814699Z","shell.execute_reply":"2022-07-17T13:45:02.899152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Problem definition","metadata":{}},{"cell_type":"code","source":"print(\"Training Data\\n\", store_sales, \"\\n\\n\")\nprint(\"Test Data\\n\", test)","metadata":{"execution":{"iopub.status.busy":"2022-07-17T13:45:02.901523Z","iopub.execute_input":"2022-07-17T13:45:02.902847Z","iopub.status.idle":"2022-07-17T13:45:02.926134Z","shell.execute_reply.started":"2022-07-17T13:45:02.902788Z","shell.execute_reply":"2022-07-17T13:45:02.925271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Forecast Requirements and Considerations\n- 16 day forecast with 1 step lead time from 16th August 2017 to 31st August 2017\n- Large parts of information missing prior to June 2015 so removed from training set\n- Validation using the last 16 days of the training set","metadata":{}},{"cell_type":"code","source":"train_start_day = datetime.datetime(2015, 6, 16)\n# train_start_day = datetime.datetime(2017, 1, 1)\ntrain_end_day = datetime.datetime(2017, 7, 30)\nfull_train_end_day = datetime.datetime(2017, 8, 15)\n\nval_start_day = datetime.datetime(2017, 7, 31)\nval_end_day = full_train_end_day\n\ntest_start_day = datetime.datetime(2017, 8, 16)\ntest_end_day = datetime.datetime(2017, 8, 31)","metadata":{"execution":{"iopub.status.busy":"2022-07-17T13:45:02.927256Z","iopub.execute_input":"2022-07-17T13:45:02.928073Z","iopub.status.idle":"2022-07-17T13:45:02.934574Z","shell.execute_reply.started":"2022-07-17T13:45:02.928023Z","shell.execute_reply":"2022-07-17T13:45:02.933291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Boosted Hybrid Class","metadata":{}},{"cell_type":"code","source":"class BoostedHybrid:\n    def __init__(self, model1, model2):\n        self.model1 = model1\n        self.model2 = model2\n        self.y_columns = None\n        self.stack_cols = None\n        self.y_resid = None\n    \n    def fit1(self, X1, y, stack_cols=None):\n        self.model1.fit(X1, y)\n        \n        y_fit = pd.DataFrame(\n            self.model1.predict(X1),\n            index=X1.index,\n            columns=y.columns        \n        )\n        \n        self.y_resid = y - y_fit\n        self.y_resid = self.y_resid.stack(stack_cols).squeeze()\n        self.y_columns = y.columns\n\n    def fit2(self, X2, ignore_first_n_rows, stack_cols=None):\n        self.model2.fit(X2.iloc[ignore_first_n_rows*1782:, :], self.y_resid.iloc[ignore_first_n_rows*1782:])\n        self.stack_cols = stack_cols\n    \n    def predict(self, X1, X2, ignore_first_n_rows):\n        y_pred = pd.DataFrame(\n            self.model1.predict(X1.iloc[ignore_first_n_rows:, :]),\n            index=X1.iloc[ignore_first_n_rows:, :].index,\n            columns=self.y_columns\n        )\n        \n        y_pred = y_pred.stack(self.stack_cols).squeeze()\n        y_pred += self.model2.predict(X2.iloc[ignore_first_n_rows*1782:, :])\n        \n        return y_pred.unstack(self.stack_cols)\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2022-07-17T13:45:02.936165Z","iopub.execute_input":"2022-07-17T13:45:02.936522Z","iopub.status.idle":"2022-07-17T13:45:02.949902Z","shell.execute_reply.started":"2022-07-17T13:45:02.936490Z","shell.execute_reply":"2022-07-17T13:45:02.948753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## X1 Preparation\nCreation of features for trend and seasonality","metadata":{}},{"cell_type":"code","source":"def create_X1_dp_features(df):\n    y = df.loc[:, 'sales']\n    fourier = CalendarFourier(freq='M', order=4)\n    \n    dp = DeterministicProcess(\n        index=y.index,\n        constant=True,\n        order=1,\n        seasonal=True,\n        additional_terms=[fourier],\n        drop=True    \n    )\n    \n    return y, dp\n\ndef create_X1_day_features(X1, start_date, end_date, test=True):\n    if test:\n        X1 = X1.rename_axis('date')\n    X1['NewYear'] = (X1.index.dayofyear == 1)\n    X1['Christmas'] = (X1.index=='2016-12-25') | (X1.index=='2015-12-25') | (X1.index=='2014-12-25') | (X1.index=='2013-12-25')\n    X1['wd'] = calender.loc[start_date:end_date]['wd'].values\n    X1['type'] = calender.loc[start_date:end_date]['type'].values\n    X1 = pd.get_dummies(X1, columns=['type'], drop_first=False)\n    \n    return X1\n\ndef create_X1(df, start_date, end_date, test=False):\n    y, dp = create_X1_dp_features(df)\n    X1 = dp.in_sample()\n    X1 = create_X1_day_features(X1, start_date, end_date, test)\n    \n    return X1, y, dp","metadata":{"execution":{"iopub.status.busy":"2022-07-17T13:45:02.951547Z","iopub.execute_input":"2022-07-17T13:45:02.952245Z","iopub.status.idle":"2022-07-17T13:45:02.967472Z","shell.execute_reply.started":"2022-07-17T13:45:02.952210Z","shell.execute_reply":"2022-07-17T13:45:02.966429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## X2 Preparation\nCreation of features for categorical relationship identification","metadata":{}},{"cell_type":"code","source":"def encode_categoricals(df, columns):\n    le = LabelEncoder()\n    for col in columns:\n        df[col] = le.fit_transform(df[col])\n    return df\n\ndef create_X2_lags(ts, lags, lead_time=1, name='y', stack_cols=None):\n    ts = ts.unstack(stack_cols)\n    df = pd.concat(\n        {\n            f'{name}_lag_{i}': ts.shift(i, freq=\"D\")\n            for i in range(lead_time, lags + lead_time)\n        },\n    axis=1)\n    df = df.stack(stack_cols).reset_index()\n    df = encode_categoricals(df, stack_cols)\n    df = df.set_index('date').sort_values(by=stack_cols)\n    \n    return df\n\ndef create_X2_promo_features(df, X2):\n    df['promo_mean_rolling_7'] = df['promo_lag_1'].rolling(window=7, center=False).mean()\n    df['promo_mean_rolling_91'] = df['promo_lag_1'].rolling(window=91, center=False).median().fillna(method='bfill')\n    return X2.merge(df, on=['date', 'store_nbr', 'family'], how='left')\n\ndef create_X2_lag_features(df, X2):\n    df['y_mean_rolling_7'] = df['y_res_lag_1'].rolling(window=7, center=False).mean()\n    df['y_median_rolling_91'] = df['y_res_lag_1'].rolling(window=91, center=False).median().fillna(method='bfill')\n    return X2.merge(df, on=['date', 'store_nbr', 'family'], how='left')\n\ndef create_X2_other_features(df):\n    df['wage_day'] = (df.index.day == df.index.daysinmonth) | (df.index.day == 15)\n    df['wage_day_lag_1'] = (df.index.day == 1) | (df.index.day == 16)\n    return df\n\ndef create_X2(df, y_resid):\n    stack_columns = ['store_nbr', 'family']\n    shifted_promo_df = create_X2_lags(df.squeeze(), lags=2, name='promo', stack_cols=stack_columns)    \n    shifted_y_df = create_X2_lags(y_resid, lags=2, name='y_res', stack_cols=stack_columns)\n    \n    df = df.reset_index(stack_columns)\n    X2 = encode_categoricals(df, stack_columns)\n    X2 = create_X2_other_features(X2)\n    X2 = create_X2_promo_features(shifted_promo_df, X2)\n    X2 = create_X2_lag_features(shifted_y_df, X2)\n    \n    return X2\n    ","metadata":{"execution":{"iopub.status.busy":"2022-07-17T13:45:02.971730Z","iopub.execute_input":"2022-07-17T13:45:02.972155Z","iopub.status.idle":"2022-07-17T13:45:02.991255Z","shell.execute_reply.started":"2022-07-17T13:45:02.972120Z","shell.execute_reply":"2022-07-17T13:45:02.990216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## DirRec Forecasting Strategy","metadata":{}},{"cell_type":"markdown","source":"Based on initial testing the combination of LinearRegressor() and KNeighborsRegressor() gave the best performance on balance, so used as a starting point. [Found here](https://www.kaggle.com/jameskeogh/store-sales-time-series-forecasting)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T05:26:48.333184Z","iopub.execute_input":"2022-07-11T05:26:48.33377Z","iopub.status.idle":"2022-07-11T05:26:48.370636Z","shell.execute_reply.started":"2022-07-11T05:26:48.333656Z","shell.execute_reply":"2022-07-11T05:26:48.369053Z"}}},{"cell_type":"code","source":"model1 = LinearRegression()\nmodel2 = XGBRegressor()\nmax_lag = 7","metadata":{"execution":{"iopub.status.busy":"2022-07-17T13:45:02.992782Z","iopub.execute_input":"2022-07-17T13:45:02.993419Z","iopub.status.idle":"2022-07-17T13:45:03.010325Z","shell.execute_reply.started":"2022-07-17T13:45:02.993381Z","shell.execute_reply":"2022-07-17T13:45:03.008786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_days = (train_end_day - train_start_day).days + 1\nvalidation_days = (val_end_day - val_start_day).days + 1\nprint(f'Training set of {training_days} days')\nprint(f'Validation set of {validation_days} days')\n\nval_model = BoostedHybrid(model1=model1, model2=model2)","metadata":{"execution":{"iopub.status.busy":"2022-07-17T13:45:03.012000Z","iopub.execute_input":"2022-07-17T13:45:03.012386Z","iopub.status.idle":"2022-07-17T13:45:03.023963Z","shell.execute_reply.started":"2022-07-17T13:45:03.012353Z","shell.execute_reply":"2022-07-17T13:45:03.023135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"store_sales_in_date_range = store_sales.unstack(['store_nbr', 'family']).loc[train_start_day:train_end_day]\nstore_data_in_val_range = store_sales.unstack(['store_nbr', 'family']).loc[val_start_day:val_end_day]\ny_val, _ = create_X1_dp_features(store_data_in_val_range)\n\nX1_train, y_train, dp_val = create_X1(store_sales_in_date_range, train_start_day, train_end_day)\nval_model.fit1(X1_train, y_train, stack_cols=['store_nbr', 'family'])\n\nX2_train = create_X2(store_sales_in_date_range.drop('sales', axis=1).stack(['store_nbr', 'family']),\n                    val_model.y_resid)\nval_model.fit2(X2_train, max_lag, stack_cols=['store_nbr', 'family'])\n\ny_fit = val_model.predict(X1_train, X2_train, max_lag).clip(0.0)","metadata":{"execution":{"iopub.status.busy":"2022-07-17T13:45:03.025164Z","iopub.execute_input":"2022-07-17T13:45:03.026052Z","iopub.status.idle":"2022-07-17T13:47:30.682816Z","shell.execute_reply.started":"2022-07-17T13:45:03.025982Z","shell.execute_reply":"2022-07-17T13:47:30.681898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dp_X1_val_date_range = dp_val.out_of_sample(steps=validation_days)\n\nfor step in range(validation_days):\n    dp_steps_so_far = dp_X1_val_date_range.loc[val_start_day:val_start_day+pd.Timedelta(days=step),:]\n    \n    X1_combined_dp = pd.concat([dp_val.in_sample(), dp_steps_so_far])\n    X2_combined = pd.concat([store_sales_in_date_range, store_data_in_val_range.loc[val_start_day:val_start_day+pd.Timedelta(days=step), :]])\n    \n    X1_val = create_X1_day_features(X1_combined_dp, train_start_day, val_start_day+pd.Timedelta(days=step))\n    X2_val = create_X2(X2_combined.drop('sales', axis=1).stack(['store_nbr', 'family']),\n                      val_model.y_resid)\n    \n    y_pred_combined = val_model.predict(X1_val, X2_val, max_lag).clip(0.0)\n    y_plus_y_val = pd.concat([y_train, y_pred_combined.iloc[-(step+1):]])\n    \n    val_model.fit1(X1_val, y_plus_y_val, stack_cols=['store_nbr', 'family'])\n    val_model.fit2(X2_val, max_lag, stack_cols=['store_nbr', 'family'])\n    \n    rmsle_valid = mean_squared_log_error(y_val.iloc[step:step+1], y_pred_combined.iloc[-1:]) ** 0.5\n    print(val_start_day+pd.Timedelta(days=step), f' RMSLE validation: {rmsle_valid:.5f}')\n    \ny_pred = y_pred_combined[val_start_day:val_end_day]","metadata":{"execution":{"iopub.status.busy":"2022-07-17T13:47:30.684154Z","iopub.execute_input":"2022-07-17T13:47:30.684483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(y_pred.apply(lambda s: truncateFloat(s)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmsle_train = mean_squared_log_error((y_train.iloc[max_lag:, :]).clip(0.0), y_fit) ** 0.5\nrmsle_valid = mean_squared_log_error(y_val.clip(0.0), y_pred) ** 0.5\nprint(f'Train RMSLE: {rmsle_train:.5f}')\nprint(f'Validation RMSLE: {rmsle_valid:.5f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_predict = y_pred.stack(['store_nbr', 'family']).reset_index()\ny_target = y_val.stack(['store_nbr', 'family']).reset_index().copy()\ny_target.rename(columns={y_target.columns[3]: 'sales'}, inplace=True)\ny_target['sales_pred'] = y_predict[0].clip(0.0)\ny_target['store_nbr'] = y_target['store_nbr'].astype(int)\n\nfamily_error = y_target.groupby('family').apply(lambda r: mean_squared_log_error(r['sales'], r['sales_pred']))\nstore_error = y_target.sort_values(by=\"store_nbr\").groupby('store_nbr').apply(lambda r: mean_squared_log_error(r['sales'], r['sales_pred']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,10))\nax = family_error.plot.barh()\nax.set_title('Validation Error for Product Families')\nax.set_xlabel('RMSLE')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,20))\nax = store_error.plot.barh()\nax.set_title('Validation Error for Stores')\nax.set_xlabel('RMSLE')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"STORE_NUMBER = '25' # 1-54\nCATEGORIES = y_train.loc(axis=1)[STORE_NUMBER].columns.to_list()\n\nfig, axs = plt.subplots(nrows=len(CATEGORIES), ncols=1, figsize=(10, 3*len(CATEGORIES)))\nfor cat, ax in zip(CATEGORIES, axs.flatten()):\n    y_train.loc(axis=1)[STORE_NUMBER].loc(axis=1)[cat].plot(ax=ax, **plot_params) # Training period sales data\n    y_fit.loc(axis=1)[STORE_NUMBER].loc(axis=1)[cat].plot(color='blue', linewidth=4, ax=ax, alpha=0.4) # Fit of the training data\n    y_val.loc(axis=1)[STORE_NUMBER].loc(axis=1)[cat].plot(ax=ax, **plot_params) # Validation period sales data\n    y_pred.loc(axis=1)[STORE_NUMBER].loc(axis=1)[cat].plot(color='red', linewidth=4, ax=ax, alpha=0.4) # Validation forecast\n    ax.set_title(f'STORE {STORE_NUMBER} {cat} SALES', fontsize=10)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = LinearRegression()\nmodel2 = KNeighborsRegressor()\nmax_lag = 7","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_days = (full_train_end_day - train_start_day).days + 1\ntest_days = (test_end_day - test_start_day).days + 1\nprint(f'Training set of {training_days} days')\nprint(f'Test set of {test_days} days')\n\ntest_model = BoostedHybrid(model1=model1, model2=model2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"store_sales_in_date_range = store_sales.unstack(['store_nbr', 'family']).loc[train_start_day:full_train_end_day]\ntest_in_date_range = test.unstack(['store_nbr', 'family']).drop('id', axis=1) \n# y_test, _ = create_X1_dp_features(test_in_date_range, test=True)\n\nX1_train, y_train, dp_test = create_X1(store_sales_in_date_range, train_start_day, full_train_end_day)\ntest_model.fit1(X1_train, y_train, stack_cols=['store_nbr', 'family'])\n\nX2_train = create_X2(store_sales_in_date_range.drop('sales', axis=1).stack(['store_nbr', 'family']),\n                    test_model.y_resid)\ntest_model.fit2(X2_train, max_lag, stack_cols=['store_nbr', 'family'])\n\ny_fit = test_model.predict(X1_train, X2_train, max_lag).clip(0.0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dp_X1_test_date_range = dp_test.out_of_sample(steps=test_days)\n\nfor step in range(test_days):\n    dp_steps_so_far = dp_X1_test_date_range.loc[test_start_day:test_start_day+pd.Timedelta(days=step),:]\n    \n    X1_combined_dp = pd.concat([dp_test.in_sample(), dp_steps_so_far])\n    X2_combined = pd.concat([store_sales_in_date_range.drop('sales', axis=1), test_in_date_range.loc[test_start_day:test_start_day+pd.Timedelta(days=step), :]])\n    \n    X1_test = create_X1_day_features(X1_combined_dp, train_start_day, test_start_day+pd.Timedelta(days=step), test=True)\n    X2_test = create_X2(X2_combined.stack(['store_nbr', 'family']),\n                      test_model.y_resid)\n    \n    y_forecast_combined = test_model.predict(X1_test, X2_test, max_lag).clip(0.0)\n    y_plus_y_test = pd.concat([y_train, y_forecast_combined.iloc[-(step+1):]])\n    \n    test_model.fit1(X1_test, y_plus_y_test, stack_cols=['store_nbr', 'family'])\n    test_model.fit2(X2_test, max_lag, stack_cols=['store_nbr', 'family'])\n    \n    print(test_start_day+pd.Timedelta(days=step))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_forecast = pd.DataFrame(y_forecast_combined[test_start_day:test_end_day].clip(0.0), index=X1_test.index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"STORE_NUMBER = '3' # 1-54\nCATEGORIES = y_train.loc(axis=1)[STORE_NUMBER].columns.to_list()\n\nfig, axs = plt.subplots(nrows=len(CATEGORIES), ncols=1, figsize=(10, 3*len(CATEGORIES)))\nfor cat, ax in zip(CATEGORIES, axs.flatten()):\n    y_train.loc(axis=1)[STORE_NUMBER].loc(axis=1)[cat].plot(ax=ax, **plot_params) # Training period sales data\n    y_fit.loc(axis=1)[STORE_NUMBER].loc(axis=1)[cat].plot(color='blue', linewidth=4, ax=ax, alpha=0.4) # Fit of the training data\n    y_forecast.loc(axis=1)[STORE_NUMBER].loc(axis=1)[cat].plot(color='green', linewidth=4, ax=ax, alpha=0.4) # Test forecast\n    ax.set_title(f'STORE {STORE_NUMBER} {cat} SALES', fontsize=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_submit = y_forecast.stack(['store_nbr', 'family'])\ny_submit = pd.DataFrame(y_submit, columns=['sales'])\ny_submit = y_submit.join(test.id).reindex(columns=['id', 'sales'])\ny_submit.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_submit.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}